# Memo 
This is a working memo for tracking Calvin's DPhil project

## 20231002 Data Collection
[original tweet dataset](https://github.com/echen102/COVID-19-TweetIDs)
What i would like to do is download self OR ask Liang to access CUHK VM again
1. download data to my local laptop
2. save them to local file (friends list downloaded already)

[Nitter](https://nitter.net/), a mirrored Twitter website which can web crawl tweets based on usernames. 
* Maneul shared his web crawler in the Slack channel, and also several paper classifying political stands
    * [Claim Extraction and Dynamic Stance Detection in COVID-19 Tweets](https://dl.acm.org/doi/abs/10.1145/3543873.3587643)
    * [The COVMis-Stance dataset: Stance Detection on Twitter for COVID-19 Misinformation](https://arxiv.org/abs/2204.02000)
    * [Stance Detection in COVID-19 Tweets](https://aclanthology.org/2021.acl-long.127/)

Haixin is uploading the data to google drive where i have a SQL data (500G) including one year of the dataset. How to deal with that dataset is a problem. Probably i won't use it, just use small data to do different truncks. 

__Daily Summary__
* i am using one hour data `coronavirus-tweet-id-2022-11-01-00.jsonl` for code testing. 



